{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity, device):\n",
    "        self.capacity = int(capacity) # capacity of the buffer\n",
    "        self.data = []\n",
    "        self.index = 0 # index of the next cell to be filled\n",
    "        self.device = device\n",
    "    def append(self, s, a, r, s_, d):\n",
    "        if len(self.data) < self.capacity:\n",
    "            self.data.append(None)\n",
    "        self.data[self.index] = (s, a, r, s_, d)\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.data, batch_size)\n",
    "        return list(map(lambda x:torch.Tensor(np.array(x)).to(self.device), list(zip(*batch))))\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_action(network, state):\n",
    "    device = \"cuda\" if next(network.parameters()).is_cuda else \"cpu\"\n",
    "    with torch.no_grad():\n",
    "        Q = network(torch.Tensor(state).unsqueeze(0).to(device))\n",
    "        return torch.argmax(Q).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dqn_agent:\n",
    "    def __init__(self, config, model):\n",
    "        device = \"cuda\" if next(model.parameters()).is_cuda else \"cpu\"\n",
    "        self.nb_actions = config['nb_actions']\n",
    "        self.gamma = config['gamma'] if 'gamma' in config.keys() else 0.95\n",
    "        self.batch_size = config['batch_size'] if 'batch_size' in config.keys() else 100\n",
    "        buffer_size = config['buffer_size'] if 'buffer_size' in config.keys() else int(1e5)\n",
    "        self.memory = ReplayBuffer(buffer_size,device)\n",
    "        self.epsilon_max = config['epsilon_max'] if 'epsilon_max' in config.keys() else 1.\n",
    "        self.epsilon_min = config['epsilon_min'] if 'epsilon_min' in config.keys() else 0.01\n",
    "        self.epsilon_stop = config['epsilon_decay_period'] if 'epsilon_decay_period' in config.keys() else 1000\n",
    "        self.epsilon_delay = config['epsilon_delay_decay'] if 'epsilon_delay_decay' in config.keys() else 20\n",
    "        self.epsilon_step = (self.epsilon_max-self.epsilon_min)/self.epsilon_stop\n",
    "        self.model = model \n",
    "        self.target_model = deepcopy(self.model).to(device)\n",
    "        self.criterion = config['criterion'] if 'criterion' in config.keys() else torch.nn.MSELoss()\n",
    "        lr = config['learning_rate'] if 'learning_rate' in config.keys() else 0.001\n",
    "        self.optimizer = config['optimizer'] if 'optimizer' in config.keys() else torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.nb_gradient_steps = config['gradient_steps'] if 'gradient_steps' in config.keys() else 1\n",
    "        self.update_target_strategy = config['update_target_strategy'] if 'update_target_strategy' in config.keys() else 'replace'\n",
    "        self.update_target_freq = config['update_target_freq'] if 'update_target_freq' in config.keys() else 20\n",
    "        self.update_target_tau = config['update_target_tau'] if 'update_target_tau' in config.keys() else 0.005\n",
    "    \n",
    "    def gradient_step(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            X, A, R, Y, D = self.memory.sample(self.batch_size)\n",
    "            QYmax = self.target_model(Y).max(1)[0].detach()\n",
    "            update = torch.addcmul(R, 1-D, QYmax, value=self.gamma)\n",
    "            QXA = self.model(X).gather(1, A.to(torch.long).unsqueeze(1))\n",
    "            loss = self.criterion(QXA, update.unsqueeze(1))\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step() \n",
    "    \n",
    "    def train(self, env, max_episode):\n",
    "        episode_return = []\n",
    "        episode = 0\n",
    "        episode_cum_reward = 0\n",
    "        state, _ = env.reset()\n",
    "        epsilon = self.epsilon_max\n",
    "        step = 0\n",
    "        while episode < max_episode:\n",
    "            # update epsilon\n",
    "            if step > self.epsilon_delay:\n",
    "                epsilon = max(self.epsilon_min, epsilon-self.epsilon_step)\n",
    "            # select epsilon-greedy action\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = greedy_action(self.model, state)\n",
    "            # step\n",
    "            next_state, reward, done, trunc, _ = env.step(action)\n",
    "            self.memory.append(state, action, reward, next_state, done)\n",
    "            episode_cum_reward += reward\n",
    "            # train\n",
    "            for _ in range(self.nb_gradient_steps): \n",
    "                self.gradient_step()\n",
    "            # update target network if needed\n",
    "            if self.update_target_strategy == 'replace':\n",
    "                if step % self.update_target_freq == 0: \n",
    "                    self.target_model.load_state_dict(self.model.state_dict())\n",
    "            if self.update_target_strategy == 'ema':\n",
    "                target_state_dict = self.target_model.state_dict()\n",
    "                model_state_dict = self.model.state_dict()\n",
    "                tau = self.update_target_tau\n",
    "                for key in model_state_dict:\n",
    "                    target_state_dict[key] = tau*model_state_dict[key] + (1-tau)*target_state_dict[key]\n",
    "                self.target_model.load_state_dict(target_state_dict)\n",
    "            # next transition\n",
    "            step += 1\n",
    "            if done or trunc:\n",
    "                episode += 1\n",
    "                print(\"Episode \", '{:3d}'.format(episode), \n",
    "                      \", epsilon \", '{:6.2f}'.format(epsilon), \n",
    "                      \", batch size \", '{:5d}'.format(len(self.memory)), \n",
    "                      \", episode return \", '{:4.1f}'.format(episode_cum_reward),\n",
    "                      sep='')\n",
    "                state, _ = env.reset()\n",
    "                episode_return.append(episode_cum_reward)\n",
    "                episode_cum_reward = 0\n",
    "            else:\n",
    "                state = next_state\n",
    "        return episode_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.wrappers import TimeLimit\n",
    "from env_hiv import HIVPatient\n",
    "\n",
    "env = TimeLimit(\n",
    "    env=HIVPatient(domain_randomization=False), max_episode_steps=200\n",
    ")  # The time wrapper limits the number of steps in an episode at 200.\n",
    "# Now is the floor is yours to implement the agent and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Episode   1, epsilon   0.82, batch size   200, episode return 8814297.5\n",
      "Episode   2, epsilon   0.62, batch size   400, episode return 9258681.0\n",
      "Episode   3, epsilon   0.43, batch size   600, episode return 5947548.7\n",
      "Episode   4, epsilon   0.23, batch size   800, episode return 7230525.7\n",
      "Episode   5, epsilon   0.03, batch size  1000, episode return 10110779.6\n",
      "Episode   6, epsilon   0.01, batch size  1200, episode return 32727322.7\n",
      "Episode   7, epsilon   0.01, batch size  1400, episode return 22235329.0\n",
      "Episode   8, epsilon   0.01, batch size  1600, episode return 13816253.0\n",
      "Episode   9, epsilon   0.01, batch size  1800, episode return 55946496.4\n",
      "Episode  10, epsilon   0.01, batch size  2000, episode return 25779568.6\n",
      "Episode  11, epsilon   0.01, batch size  2200, episode return 31150129.2\n",
      "Episode  12, epsilon   0.01, batch size  2400, episode return 34933470.6\n",
      "Episode  13, epsilon   0.01, batch size  2600, episode return 23346441.4\n",
      "Episode  14, epsilon   0.01, batch size  2800, episode return 14142991.3\n",
      "Episode  15, epsilon   0.01, batch size  3000, episode return 11979141.2\n",
      "Episode  16, epsilon   0.01, batch size  3200, episode return 10977709.9\n",
      "Episode  17, epsilon   0.01, batch size  3400, episode return 10267742.2\n",
      "Episode  18, epsilon   0.01, batch size  3600, episode return 10832628.8\n",
      "Episode  19, epsilon   0.01, batch size  3800, episode return 8424837.6\n",
      "Episode  20, epsilon   0.01, batch size  4000, episode return 7295817.1\n",
      "Episode  21, epsilon   0.01, batch size  4200, episode return 6828230.1\n",
      "Episode  22, epsilon   0.01, batch size  4400, episode return 23120357.4\n",
      "Episode  23, epsilon   0.01, batch size  4600, episode return 11977357.2\n",
      "Episode  24, epsilon   0.01, batch size  4800, episode return 13791043.8\n",
      "Episode  25, epsilon   0.01, batch size  5000, episode return 13306989.2\n",
      "Episode  26, epsilon   0.01, batch size  5200, episode return 12355005.4\n",
      "Episode  27, epsilon   0.01, batch size  5400, episode return 11795463.1\n",
      "Episode  28, epsilon   0.01, batch size  5600, episode return 13192314.1\n",
      "Episode  29, epsilon   0.01, batch size  5800, episode return 15689948.0\n",
      "Episode  30, epsilon   0.01, batch size  6000, episode return 16582462.5\n",
      "Episode  31, epsilon   0.01, batch size  6200, episode return 12950767.2\n",
      "Episode  32, epsilon   0.01, batch size  6400, episode return 12513910.8\n",
      "Episode  33, epsilon   0.01, batch size  6600, episode return 10725801.9\n",
      "Episode  34, epsilon   0.01, batch size  6800, episode return 9491991.0\n",
      "Episode  35, epsilon   0.01, batch size  7000, episode return 14716274.6\n",
      "Episode  36, epsilon   0.01, batch size  7200, episode return 11448789.7\n",
      "Episode  37, epsilon   0.01, batch size  7400, episode return 15799556.2\n",
      "Episode  38, epsilon   0.01, batch size  7600, episode return 24681761.2\n",
      "Episode  39, epsilon   0.01, batch size  7800, episode return 17051693.3\n",
      "Episode  40, epsilon   0.01, batch size  8000, episode return 12513067.6\n",
      "Episode  41, epsilon   0.01, batch size  8200, episode return 13642142.1\n",
      "Episode  42, epsilon   0.01, batch size  8400, episode return 10148966.4\n",
      "Episode  43, epsilon   0.01, batch size  8600, episode return 15686319.4\n",
      "Episode  44, epsilon   0.01, batch size  8800, episode return 15098897.4\n",
      "Episode  45, epsilon   0.01, batch size  9000, episode return 9137737.7\n",
      "Episode  46, epsilon   0.01, batch size  9200, episode return 10989723.6\n",
      "Episode  47, epsilon   0.01, batch size  9400, episode return 21483111.0\n",
      "Episode  48, epsilon   0.01, batch size  9600, episode return 13902664.8\n",
      "Episode  49, epsilon   0.01, batch size  9800, episode return 14966911.9\n",
      "Episode  50, epsilon   0.01, batch size 10000, episode return 6063984.7\n",
      "Episode  51, epsilon   0.01, batch size 10200, episode return 6777395.6\n",
      "Episode  52, epsilon   0.01, batch size 10400, episode return 7727602.7\n",
      "Episode  53, epsilon   0.01, batch size 10600, episode return 6777395.6\n",
      "Episode  54, epsilon   0.01, batch size 10800, episode return 7884322.7\n",
      "Episode  55, epsilon   0.01, batch size 11000, episode return 11288926.3\n",
      "Episode  56, epsilon   0.01, batch size 11200, episode return 6169331.0\n",
      "Episode  57, epsilon   0.01, batch size 11400, episode return 8459736.5\n",
      "Episode  58, epsilon   0.01, batch size 11600, episode return 6777395.6\n",
      "Episode  59, epsilon   0.01, batch size 11800, episode return 6777395.6\n",
      "Episode  60, epsilon   0.01, batch size 12000, episode return 6376359.3\n",
      "Episode  61, epsilon   0.01, batch size 12200, episode return 6523730.7\n",
      "Episode  62, epsilon   0.01, batch size 12400, episode return 8183963.1\n",
      "Episode  63, epsilon   0.01, batch size 12600, episode return 8112436.9\n",
      "Episode  64, epsilon   0.01, batch size 12800, episode return 14459688.5\n",
      "Episode  65, epsilon   0.01, batch size 13000, episode return 7296212.5\n",
      "Episode  66, epsilon   0.01, batch size 13200, episode return 15224317.9\n",
      "Episode  67, epsilon   0.01, batch size 13400, episode return 6777395.6\n",
      "Episode  68, epsilon   0.01, batch size 13600, episode return 8069755.9\n",
      "Episode  69, epsilon   0.01, batch size 13800, episode return 10096497.3\n",
      "Episode  70, epsilon   0.01, batch size 14000, episode return 13835270.8\n",
      "Episode  71, epsilon   0.01, batch size 14200, episode return 9947445.9\n",
      "Episode  72, epsilon   0.01, batch size 14400, episode return 9209804.4\n",
      "Episode  73, epsilon   0.01, batch size 14600, episode return 7620970.1\n",
      "Episode  74, epsilon   0.01, batch size 14800, episode return 10462646.7\n",
      "Episode  75, epsilon   0.01, batch size 15000, episode return 10290066.0\n",
      "Episode  76, epsilon   0.01, batch size 15200, episode return 10747075.8\n",
      "Episode  77, epsilon   0.01, batch size 15400, episode return 8970612.7\n",
      "Episode  78, epsilon   0.01, batch size 15600, episode return 9280486.3\n",
      "Episode  79, epsilon   0.01, batch size 15800, episode return 6777395.6\n",
      "Episode  80, epsilon   0.01, batch size 16000, episode return 10309724.3\n",
      "Episode  81, epsilon   0.01, batch size 16200, episode return 11257157.0\n",
      "Episode  82, epsilon   0.01, batch size 16400, episode return 9563716.6\n",
      "Episode  83, epsilon   0.01, batch size 16600, episode return 8928471.9\n",
      "Episode  84, epsilon   0.01, batch size 16800, episode return 6777395.6\n",
      "Episode  85, epsilon   0.01, batch size 17000, episode return 7846760.1\n",
      "Episode  86, epsilon   0.01, batch size 17200, episode return 9298201.6\n",
      "Episode  87, epsilon   0.01, batch size 17400, episode return 6777395.6\n",
      "Episode  88, epsilon   0.01, batch size 17600, episode return 8175594.6\n",
      "Episode  89, epsilon   0.01, batch size 17800, episode return 6532546.2\n",
      "Episode  90, epsilon   0.01, batch size 18000, episode return 7570071.9\n",
      "Episode  91, epsilon   0.01, batch size 18200, episode return 13650309.8\n",
      "Episode  92, epsilon   0.01, batch size 18400, episode return 6627107.9\n",
      "Episode  93, epsilon   0.01, batch size 18600, episode return 9236231.1\n",
      "Episode  94, epsilon   0.01, batch size 18800, episode return 9067214.4\n",
      "Episode  95, epsilon   0.01, batch size 19000, episode return 9370548.2\n",
      "Episode  96, epsilon   0.01, batch size 19200, episode return 9338382.1\n",
      "Episode  97, epsilon   0.01, batch size 19400, episode return 9065703.8\n",
      "Episode  98, epsilon   0.01, batch size 19600, episode return 9419862.4\n",
      "Episode  99, epsilon   0.01, batch size 19800, episode return 10108906.6\n",
      "Episode 100, epsilon   0.01, batch size 20000, episode return 9637879.8\n",
      "Episode 101, epsilon   0.01, batch size 20200, episode return 10585421.6\n",
      "Episode 102, epsilon   0.01, batch size 20400, episode return 10073080.3\n",
      "Episode 103, epsilon   0.01, batch size 20600, episode return 10167439.6\n",
      "Episode 104, epsilon   0.01, batch size 20800, episode return 6587372.9\n",
      "Episode 105, epsilon   0.01, batch size 21000, episode return 6777395.6\n",
      "Episode 106, epsilon   0.01, batch size 21200, episode return 7191478.7\n",
      "Episode 107, epsilon   0.01, batch size 21400, episode return 6777395.6\n",
      "Episode 108, epsilon   0.01, batch size 21600, episode return 6777395.6\n",
      "Episode 109, epsilon   0.01, batch size 21800, episode return 6268081.5\n",
      "Episode 110, epsilon   0.01, batch size 22000, episode return 6777395.6\n",
      "Episode 111, epsilon   0.01, batch size 22200, episode return 8078055.0\n",
      "Episode 112, epsilon   0.01, batch size 22400, episode return 7906888.4\n",
      "Episode 113, epsilon   0.01, batch size 22600, episode return 14077147.6\n",
      "Episode 114, epsilon   0.01, batch size 22800, episode return 11166295.4\n",
      "Episode 115, epsilon   0.01, batch size 23000, episode return 11806514.4\n",
      "Episode 116, epsilon   0.01, batch size 23200, episode return 10750842.1\n",
      "Episode 117, epsilon   0.01, batch size 23400, episode return 10450085.1\n",
      "Episode 118, epsilon   0.01, batch size 23600, episode return 10502804.4\n",
      "Episode 119, epsilon   0.01, batch size 23800, episode return 17717390.0\n",
      "Episode 120, epsilon   0.01, batch size 24000, episode return 12441723.9\n",
      "Episode 121, epsilon   0.01, batch size 24200, episode return 9481923.4\n",
      "Episode 122, epsilon   0.01, batch size 24400, episode return 6777395.6\n",
      "Episode 123, epsilon   0.01, batch size 24600, episode return 7196921.8\n",
      "Episode 124, epsilon   0.01, batch size 24800, episode return 7863817.2\n",
      "Episode 125, epsilon   0.01, batch size 25000, episode return 8326959.8\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Declare network\n",
    "state_dim = env.observation_space.shape[0]\n",
    "n_action = env.action_space.n \n",
    "nb_neurons=24\n",
    "DQN = torch.nn.Sequential(nn.Linear(state_dim, nb_neurons),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(nb_neurons, nb_neurons),\n",
    "                          nn.ReLU(), \n",
    "                          nn.Linear(nb_neurons, n_action)).to(device)\n",
    "\n",
    "# DQN config\n",
    "config = {'nb_actions': env.action_space.n,\n",
    "          'learning_rate': 0.001,\n",
    "          'gamma': 0.99,\n",
    "          'buffer_size': 1000000,\n",
    "          'epsilon_min': 0.01,\n",
    "          'epsilon_max': 1.,\n",
    "          'epsilon_decay_period': 1000,\n",
    "          'epsilon_delay_decay': 20,\n",
    "          'batch_size': 512,\n",
    "          'gradient_steps': 3,\n",
    "          'update_target_strategy': 'ema', # or 'ema'\n",
    "          'update_target_freq': 50,\n",
    "          'update_target_tau': 0.005,\n",
    "          'criterion': torch.nn.SmoothL1Loss()}\n",
    "\n",
    "# Train agent\n",
    "agent = dqn_agent(config, DQN)\n",
    "scores = agent.train(env, 200)\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(DQN, os.path.join(os.getcwd(), \"models/DQN3.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
