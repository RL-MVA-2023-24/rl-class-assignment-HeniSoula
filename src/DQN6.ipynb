{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity, device):\n",
    "        self.capacity = int(capacity) # capacity of the buffer\n",
    "        self.data = []\n",
    "        self.index = 0 # index of the next cell to be filled\n",
    "        self.device = device\n",
    "    def append(self, s, a, r, s_, d):\n",
    "        if len(self.data) < self.capacity:\n",
    "            self.data.append(None)\n",
    "        self.data[self.index] = (s, a, r, s_, d)\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.data, batch_size)\n",
    "        return list(map(lambda x:torch.Tensor(np.array(x)).to(self.device), list(zip(*batch))))\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_action(network, state):\n",
    "    device = \"cuda\" if next(network.parameters()).is_cuda else \"cpu\"\n",
    "    with torch.no_grad():\n",
    "        Q = network(torch.Tensor(state).unsqueeze(0).to(device))\n",
    "        return torch.argmax(Q).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dqn_agent:\n",
    "    def __init__(self, config, model):\n",
    "        device = \"cuda\" if next(model.parameters()).is_cuda else \"cpu\"\n",
    "        self.nb_actions = config['nb_actions']\n",
    "        self.gamma = config['gamma'] if 'gamma' in config.keys() else 0.95\n",
    "        self.batch_size = config['batch_size'] if 'batch_size' in config.keys() else 100\n",
    "        buffer_size = config['buffer_size'] if 'buffer_size' in config.keys() else int(1e5)\n",
    "        self.memory = ReplayBuffer(buffer_size,device)\n",
    "        self.epsilon_max = config['epsilon_max'] if 'epsilon_max' in config.keys() else 1.\n",
    "        self.epsilon_min = config['epsilon_min'] if 'epsilon_min' in config.keys() else 0.01\n",
    "        self.epsilon_stop = config['epsilon_decay_period'] if 'epsilon_decay_period' in config.keys() else 1000\n",
    "        self.epsilon_delay = config['epsilon_delay_decay'] if 'epsilon_delay_decay' in config.keys() else 20\n",
    "        self.epsilon_step = (self.epsilon_max-self.epsilon_min)/self.epsilon_stop\n",
    "        self.model = model \n",
    "        self.target_model = deepcopy(self.model).to(device)\n",
    "        self.criterion = config['criterion'] if 'criterion' in config.keys() else torch.nn.MSELoss()\n",
    "        lr = config['learning_rate'] if 'learning_rate' in config.keys() else 0.001\n",
    "        self.optimizer = config['optimizer'] if 'optimizer' in config.keys() else torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.nb_gradient_steps = config['gradient_steps'] if 'gradient_steps' in config.keys() else 1\n",
    "        self.update_target_strategy = config['update_target_strategy'] if 'update_target_strategy' in config.keys() else 'replace'\n",
    "        self.update_target_freq = config['update_target_freq'] if 'update_target_freq' in config.keys() else 20\n",
    "        self.update_target_tau = config['update_target_tau'] if 'update_target_tau' in config.keys() else 0.005\n",
    "    \n",
    "    def gradient_step(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            X, A, R, Y, D = self.memory.sample(self.batch_size)\n",
    "            QYmax = self.target_model(Y).max(1)[0].detach()\n",
    "            update = torch.addcmul(R, 1-D, QYmax, value=self.gamma)\n",
    "            QXA = self.model(X).gather(1, A.to(torch.long).unsqueeze(1))\n",
    "            loss = self.criterion(QXA, update.unsqueeze(1))\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step() \n",
    "    \n",
    "    def train(self, env, max_episode):\n",
    "        episode_return = []\n",
    "        episode = 0\n",
    "        episode_cum_reward = 0\n",
    "        state, _ = env.reset()\n",
    "        epsilon = self.epsilon_max\n",
    "        step = 0\n",
    "        while episode < max_episode:\n",
    "            # update epsilon\n",
    "            if step > self.epsilon_delay:\n",
    "                epsilon = max(self.epsilon_min, epsilon-self.epsilon_step)\n",
    "            # select epsilon-greedy action\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = greedy_action(self.model, state)\n",
    "            # step\n",
    "            next_state, reward, done, trunc, _ = env.step(action)\n",
    "            self.memory.append(state, action, reward, next_state, done)\n",
    "            episode_cum_reward += reward\n",
    "            # train\n",
    "            for _ in range(self.nb_gradient_steps): \n",
    "                self.gradient_step()\n",
    "            # update target network if needed\n",
    "            if self.update_target_strategy == 'replace':\n",
    "                if step % self.update_target_freq == 0: \n",
    "                    self.target_model.load_state_dict(self.model.state_dict())\n",
    "            if self.update_target_strategy == 'ema':\n",
    "                target_state_dict = self.target_model.state_dict()\n",
    "                model_state_dict = self.model.state_dict()\n",
    "                tau = self.update_target_tau\n",
    "                for key in model_state_dict:\n",
    "                    target_state_dict[key] = tau*model_state_dict[key] + (1-tau)*target_state_dict[key]\n",
    "                self.target_model.load_state_dict(target_state_dict)\n",
    "            # next transition\n",
    "            step += 1\n",
    "            if done or trunc:\n",
    "                if episode > 0:\n",
    "                    if episode_cum_reward > best_reward:\n",
    "                        best_reward = episode_cum_reward\n",
    "                        torch.save(self.model, os.path.join(os.getcwd(), \"models/DQN7.pt\"))\n",
    "                else:\n",
    "                    best_reward = episode_cum_reward\n",
    "                    torch.save(self.model, os.path.join(os.getcwd(), \"models/DQN7.pt\"))\n",
    "\n",
    "                episode += 1\n",
    "                print(\"Episode \", '{:3d}'.format(episode), \n",
    "                      \", epsilon \", '{:6.2f}'.format(epsilon), \n",
    "                      \", batch size \", '{:5d}'.format(len(self.memory)), \n",
    "                      \", episode return \", \"{:.2e}\".format(episode_cum_reward),\n",
    "                      sep='')\n",
    "                state, _ = env.reset()\n",
    "                episode_return.append(episode_cum_reward)\n",
    "                episode_cum_reward = 0\n",
    "\n",
    "            else:\n",
    "                state = next_state\n",
    "        return episode_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.wrappers import TimeLimit\n",
    "from env_hiv import HIVPatient\n",
    "\n",
    "env = TimeLimit(\n",
    "    env=HIVPatient(domain_randomization=False), max_episode_steps=200\n",
    ")  # The time wrapper limits the number of steps in an episode at 200.\n",
    "# Now is the floor is yours to implement the agent and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Episode   1, epsilon   1.00, batch size   200, episode return 1.07e+07\n",
      "Episode   2, epsilon   1.00, batch size   400, episode return 9.41e+06\n",
      "Episode   3, epsilon   1.00, batch size   600, episode return 1.07e+07\n",
      "Episode   4, epsilon   1.00, batch size   800, episode return 1.02e+07\n",
      "Episode   5, epsilon   1.00, batch size  1000, episode return 8.95e+06\n",
      "Episode   6, epsilon   1.00, batch size  1200, episode return 7.67e+06\n",
      "Episode   7, epsilon   1.00, batch size  1400, episode return 7.63e+06\n",
      "Episode   8, epsilon   1.00, batch size  1600, episode return 7.75e+06\n",
      "Episode   9, epsilon   1.00, batch size  1800, episode return 1.01e+07\n",
      "Episode  10, epsilon   1.00, batch size  2000, episode return 1.15e+07\n",
      "Episode  11, epsilon   0.98, batch size  2200, episode return 9.74e+06\n",
      "Episode  12, epsilon   0.96, batch size  2400, episode return 1.28e+07\n",
      "Episode  13, epsilon   0.94, batch size  2600, episode return 1.00e+07\n",
      "Episode  14, epsilon   0.92, batch size  2800, episode return 1.31e+07\n",
      "Episode  15, epsilon   0.91, batch size  3000, episode return 1.21e+07\n",
      "Episode  16, epsilon   0.89, batch size  3200, episode return 1.13e+07\n",
      "Episode  17, epsilon   0.87, batch size  3400, episode return 9.47e+06\n",
      "Episode  18, epsilon   0.85, batch size  3600, episode return 1.39e+07\n",
      "Episode  19, epsilon   0.83, batch size  3800, episode return 1.80e+07\n",
      "Episode  20, epsilon   0.81, batch size  4000, episode return 1.21e+07\n",
      "Episode  21, epsilon   0.79, batch size  4200, episode return 1.57e+07\n",
      "Episode  22, epsilon   0.77, batch size  4400, episode return 1.64e+07\n",
      "Episode  23, epsilon   0.75, batch size  4600, episode return 1.52e+07\n",
      "Episode  24, epsilon   0.73, batch size  4800, episode return 1.39e+07\n",
      "Episode  25, epsilon   0.72, batch size  5000, episode return 1.67e+07\n",
      "Episode  26, epsilon   0.70, batch size  5200, episode return 1.81e+07\n",
      "Episode  27, epsilon   0.68, batch size  5400, episode return 1.29e+07\n",
      "Episode  28, epsilon   0.66, batch size  5600, episode return 2.39e+07\n",
      "Episode  29, epsilon   0.64, batch size  5800, episode return 2.10e+07\n",
      "Episode  30, epsilon   0.62, batch size  6000, episode return 1.90e+07\n",
      "Episode  31, epsilon   0.60, batch size  6200, episode return 1.76e+07\n",
      "Episode  32, epsilon   0.58, batch size  6400, episode return 1.55e+07\n",
      "Episode  33, epsilon   0.56, batch size  6600, episode return 3.29e+07\n",
      "Episode  34, epsilon   0.54, batch size  6800, episode return 3.58e+07\n",
      "Episode  35, epsilon   0.53, batch size  7000, episode return 6.41e+07\n",
      "Episode  36, epsilon   0.51, batch size  7200, episode return 3.94e+07\n",
      "Episode  37, epsilon   0.49, batch size  7400, episode return 2.80e+07\n",
      "Episode  38, epsilon   0.47, batch size  7600, episode return 2.98e+07\n",
      "Episode  39, epsilon   0.45, batch size  7800, episode return 4.38e+07\n",
      "Episode  40, epsilon   0.43, batch size  8000, episode return 5.94e+07\n",
      "Episode  41, epsilon   0.41, batch size  8200, episode return 4.38e+07\n",
      "Episode  42, epsilon   0.39, batch size  8400, episode return 3.51e+07\n",
      "Episode  43, epsilon   0.37, batch size  8600, episode return 1.18e+08\n",
      "Episode  44, epsilon   0.35, batch size  8800, episode return 1.89e+08\n",
      "Episode  45, epsilon   0.34, batch size  9000, episode return 4.32e+07\n",
      "Episode  46, epsilon   0.32, batch size  9200, episode return 7.55e+07\n",
      "Episode  47, epsilon   0.30, batch size  9400, episode return 4.83e+07\n",
      "Episode  48, epsilon   0.28, batch size  9600, episode return 1.30e+08\n",
      "Episode  49, epsilon   0.26, batch size  9800, episode return 6.46e+07\n",
      "Episode  50, epsilon   0.24, batch size 10000, episode return 1.09e+08\n",
      "Episode  51, epsilon   0.22, batch size 10200, episode return 2.04e+08\n",
      "Episode  52, epsilon   0.20, batch size 10240, episode return 1.14e+08\n",
      "Episode  53, epsilon   0.18, batch size 10240, episode return 2.31e+08\n",
      "Episode  54, epsilon   0.16, batch size 10240, episode return 1.33e+08\n",
      "Episode  55, epsilon   0.15, batch size 10240, episode return 1.72e+08\n",
      "Episode  56, epsilon   0.13, batch size 10240, episode return 2.15e+08\n",
      "Episode  57, epsilon   0.11, batch size 10240, episode return 6.26e+08\n",
      "Episode  58, epsilon   0.09, batch size 10240, episode return 8.03e+08\n",
      "Episode  59, epsilon   0.07, batch size 10240, episode return 1.50e+09\n",
      "Episode  60, epsilon   0.05, batch size 10240, episode return 8.70e+07\n",
      "Episode  61, epsilon   0.05, batch size 10240, episode return 2.36e+08\n",
      "Episode  62, epsilon   0.05, batch size 10240, episode return 3.05e+09\n",
      "Episode  63, epsilon   0.05, batch size 10240, episode return 1.65e+09\n",
      "Episode  64, epsilon   0.05, batch size 10240, episode return 3.43e+08\n",
      "Episode  65, epsilon   0.05, batch size 10240, episode return 7.48e+09\n",
      "Episode  66, epsilon   0.05, batch size 10240, episode return 1.89e+09\n",
      "Episode  67, epsilon   0.05, batch size 10240, episode return 1.83e+08\n",
      "Episode  68, epsilon   0.05, batch size 10240, episode return 3.51e+09\n",
      "Episode  69, epsilon   0.05, batch size 10240, episode return 7.21e+09\n",
      "Episode  70, epsilon   0.05, batch size 10240, episode return 1.22e+09\n",
      "Episode  71, epsilon   0.05, batch size 10240, episode return 8.37e+08\n",
      "Episode  72, epsilon   0.05, batch size 10240, episode return 5.08e+09\n",
      "Episode  73, epsilon   0.05, batch size 10240, episode return 5.56e+09\n",
      "Episode  74, epsilon   0.05, batch size 10240, episode return 1.00e+08\n",
      "Episode  75, epsilon   0.05, batch size 10240, episode return 2.43e+09\n",
      "Episode  76, epsilon   0.05, batch size 10240, episode return 1.33e+09\n",
      "Episode  77, epsilon   0.05, batch size 10240, episode return 6.80e+09\n",
      "Episode  78, epsilon   0.05, batch size 10240, episode return 1.11e+09\n",
      "Episode  79, epsilon   0.05, batch size 10240, episode return 4.64e+08\n",
      "Episode  80, epsilon   0.05, batch size 10240, episode return 5.15e+09\n",
      "Episode  81, epsilon   0.05, batch size 10240, episode return 2.37e+09\n",
      "Episode  82, epsilon   0.05, batch size 10240, episode return 2.11e+09\n",
      "Episode  83, epsilon   0.05, batch size 10240, episode return 2.30e+07\n",
      "Episode  84, epsilon   0.05, batch size 10240, episode return 3.76e+07\n",
      "Episode  85, epsilon   0.05, batch size 10240, episode return 1.03e+09\n",
      "Episode  86, epsilon   0.05, batch size 10240, episode return 2.42e+08\n",
      "Episode  87, epsilon   0.05, batch size 10240, episode return 3.62e+09\n",
      "Episode  88, epsilon   0.05, batch size 10240, episode return 1.99e+08\n",
      "Episode  89, epsilon   0.05, batch size 10240, episode return 1.72e+09\n",
      "Episode  90, epsilon   0.05, batch size 10240, episode return 5.38e+09\n",
      "Episode  91, epsilon   0.05, batch size 10240, episode return 5.99e+07\n",
      "Episode  92, epsilon   0.05, batch size 10240, episode return 6.29e+07\n",
      "Episode  93, epsilon   0.05, batch size 10240, episode return 8.69e+07\n",
      "Episode  94, epsilon   0.05, batch size 10240, episode return 8.58e+07\n",
      "Episode  95, epsilon   0.05, batch size 10240, episode return 1.11e+08\n",
      "Episode  96, epsilon   0.05, batch size 10240, episode return 2.27e+08\n",
      "Episode  97, epsilon   0.05, batch size 10240, episode return 1.23e+08\n",
      "Episode  98, epsilon   0.05, batch size 10240, episode return 1.20e+09\n",
      "Episode  99, epsilon   0.05, batch size 10240, episode return 2.37e+08\n",
      "Episode 100, epsilon   0.05, batch size 10240, episode return 1.68e+08\n",
      "Episode 101, epsilon   0.05, batch size 10240, episode return 1.24e+08\n",
      "Episode 102, epsilon   0.05, batch size 10240, episode return 1.31e+08\n",
      "Episode 103, epsilon   0.05, batch size 10240, episode return 1.06e+09\n",
      "Episode 104, epsilon   0.05, batch size 10240, episode return 5.47e+09\n",
      "Episode 105, epsilon   0.05, batch size 10240, episode return 3.33e+08\n",
      "Episode 106, epsilon   0.05, batch size 10240, episode return 1.48e+08\n",
      "Episode 107, epsilon   0.05, batch size 10240, episode return 1.00e+08\n",
      "Episode 108, epsilon   0.05, batch size 10240, episode return 5.38e+07\n",
      "Episode 109, epsilon   0.05, batch size 10240, episode return 6.47e+07\n",
      "Episode 110, epsilon   0.05, batch size 10240, episode return 3.14e+07\n",
      "Episode 111, epsilon   0.05, batch size 10240, episode return 3.01e+07\n",
      "Episode 112, epsilon   0.05, batch size 10240, episode return 1.09e+08\n",
      "Episode 113, epsilon   0.05, batch size 10240, episode return 1.13e+08\n",
      "Episode 114, epsilon   0.05, batch size 10240, episode return 4.18e+07\n",
      "Episode 115, epsilon   0.05, batch size 10240, episode return 1.82e+08\n",
      "Episode 116, epsilon   0.05, batch size 10240, episode return 1.15e+08\n",
      "Episode 117, epsilon   0.05, batch size 10240, episode return 5.40e+08\n",
      "Episode 118, epsilon   0.05, batch size 10240, episode return 2.78e+07\n",
      "Episode 119, epsilon   0.05, batch size 10240, episode return 9.93e+07\n",
      "Episode 120, epsilon   0.05, batch size 10240, episode return 1.47e+08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://user-heptis-840631-0.user.lab.sspcloud.fr/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Train agent\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://user-heptis-840631-0.user.lab.sspcloud.fr/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m agent \u001b[39m=\u001b[39m dqn_agent(config, DQN)\n\u001b[0;32m---> <a href='vscode-notebook-cell://user-heptis-840631-0.user.lab.sspcloud.fr/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m scores \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mtrain(env, \u001b[39m500\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://user-heptis-840631-0.user.lab.sspcloud.fr/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(scores)\n",
      "\u001b[1;32m/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://user-heptis-840631-0.user.lab.sspcloud.fr/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://user-heptis-840631-0.user.lab.sspcloud.fr/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_gradient_steps): \n\u001b[0;32m---> <a href='vscode-notebook-cell://user-heptis-840631-0.user.lab.sspcloud.fr/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_step()\n\u001b[1;32m     <a href='vscode-notebook-cell://user-heptis-840631-0.user.lab.sspcloud.fr/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# update target network if needed\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://user-heptis-840631-0.user.lab.sspcloud.fr/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_target_strategy \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;32m/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://user-heptis-840631-0.user.lab.sspcloud.fr/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(QXA, update\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://user-heptis-840631-0.user.lab.sspcloud.fr/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://user-heptis-840631-0.user.lab.sspcloud.fr/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://user-heptis-840631-0.user.lab.sspcloud.fr/home/onyxia/work/rl-class-assignment-HeniSoula/src/DQN6.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Declare network\n",
    "state_dim = env.observation_space.shape[0]\n",
    "n_action = env.action_space.n \n",
    "nb_neurons=128\n",
    "DQN = torch.nn.Sequential(nn.Linear(state_dim, nb_neurons),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(nb_neurons, nb_neurons),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(nb_neurons, n_action)).to(device)\n",
    "\n",
    "# DQN config\n",
    "config = {'nb_actions': n_action,\n",
    "        'learning_rate': 5e-4,\n",
    "        'gamma': 0.95,\n",
    "        'buffer_size': 2048*5,\n",
    "        'epsilon_min': 0.05,\n",
    "        'epsilon_max': 1,\n",
    "        'epsilon_decay_period': 200*50,\n",
    "        'epsilon_delay_decay': 200*10,\n",
    "        'batch_size': 2048,\n",
    "        'gradient_steps': 80,\n",
    "        'update_target_strategy': 'ema', # or 'ema'\n",
    "        'update_target_freq': 20,\n",
    "        'update_target_tau': 0.01,\n",
    "        'criterion': torch.nn.SmoothL1Loss()}\n",
    "\n",
    "# Train agent\n",
    "agent = dqn_agent(config, DQN)\n",
    "scores = agent.train(env, 500)\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
